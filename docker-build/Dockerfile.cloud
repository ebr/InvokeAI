# Copyright (c) 2022 Eugene Brodsky (https://github.com/ebr)

FROM nvidia/cuda:11.7.1-runtime-ubuntu22.04 AS base

ENV DEBIAN_FRONTEND=noninteractive
# # no __pycache__ - unclear if there is a benefit
# ENV PYTHONDONTWRITEBYTECODE=1
# unbuffered output, ensures stdout and stderr are printed in the correct order
ENV PYTHONUNBUFFERED=1

RUN apt update && apt install -y \
    git \
    curl \
    ncdu \
    iotop \
    bzip2 \
    libglib2.0-0 \
    libgl1-mesa-glx \
    python3-venv \
    python3-pip \
    && apt-get clean

WORKDIR /invokeai

### Cache the dependencies first
# Avoid re-downloading the dependencies when unrelated files change in context
#
# We could use relative paths in the environment file, but it's not currently set up that way.
# So we copy it to the working directory to maintain compatibility with other installation methods
COPY environments-and-requirements/environment-lin-cuda.yml environment.yml

# ENV MAMBA_ROOT_PREFIX=/opt/conda
ENV VIRTUAL_ENV=.venv

### Copy the rest of the context and install local package
COPY . .
RUN --mount=type=cache,target=$PYTHON_VENV \
    python3 -m venv $PYTHON_VENV &&\
    . $PYTHON_VENV/bin/activate &&\
    pip install --extra-index-url https://download.pytorch.org/whl/cu116 \
        torch==1.12.0+cu116 \
        torchvision==0.13.0+cu116 &&\
    pip install -e .

# RUN --mount=type=cache,target=$MAMBA_ROOT_PREFIX micromamba -n invokeai run pip install -e .

### Default model config
RUN cp configs/models.yaml.example configs/models.yaml

ENTRYPOINT ["bash"]

EXPOSE 9090

CMD [ "-c", "python3 scripts/invoke.py --web --host 0.0.0.0"]
