# Copyright (c) 2022 Eugene Brodsky (https://github.com/ebr)

FROM nvidia/cuda:11.7.1-runtime-ubuntu22.04 AS base

ENV DEBIAN_FRONTEND=noninteractive
# # no __pycache__ - unclear if there is a benefit
# ENV PYTHONDONTWRITEBYTECODE=1
# unbuffered output, ensures stdout and stderr are printed in the correct order
ENV PYTHONUNBUFFERED=1

RUN apt update && apt install -y \
    git \
    curl \
    ncdu \
    iotop \
    bzip2 \
    libglib2.0-0 \
    libgl1-mesa-glx \
    && apt-get clean

# Micromamba is a minimal conda implementation
RUN curl -Ls https://micro.mamba.pm/api/micromamba/linux-64/latest | tar -xvj bin/micromamba

WORKDIR /invokeai

### Cache the dependencies first
# Avoid re-downloading the dependencies when unrelated files change in context
#
# We could use relative paths in the environment file, but it's not currently set up that way.
# So we copy it to the working directory to maintain compatibility with other installation methods
COPY environments-and-requirements/environment-lin-cuda.yml environment.yml

# ENV MAMBA_ROOT_PREFIX=/opt/conda
ENV PYTHON_VENV=.venv


# Patch the env file to remove installation of local package
RUN sed -i '/-e \./d' environment.yml

# # RUN micromamba create -y -f environment.yml &&\
# RUN --mount=type=cache,target=$MAMBA_ROOT_PREFIX micromamba create -y -f environment.yml
    # micromamba clean --all -f -y &&\
    # rm -rf ${MAMBA_ROOT_PREFIX}/pkgs

### Copy the rest of the context and install local package
RUN apt install -y python3-venv python3-pip
COPY . .
RUN --mount=type=cache,target=$PYTHON_VENV \
    python3 -m venv $PYTHON_VENV &&\
    pip install torch==1.12.0+cu116 torchvision==0.13.0+cu116 --extra-index-url https://download.pytorch.org/whl/cu116 &&\
    pip install -e .

RUN . $PYTHON_VENV/bin/activate
# RUN --mount=type=cache,target=$MAMBA_ROOT_PREFIX micromamba -n invokeai run pip install -e .

### Default model config
RUN cp configs/models.yaml.example configs/models.yaml

ENTRYPOINT ["bash"]

EXPOSE 9090

CMD [ "-c", "python3 scripts/invoke.py --web --host 0.0.0.0"]
