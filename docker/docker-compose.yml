version: '3.8'

services:
  invokeai:
    image: "local/invokeai:latest"
    ## edit this to run on a container runtime other than NVIDIA.
    ## not yet tested with rocm/AMD GPUs
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    build:
      context: ..
      dockerfile: docker/Dockerfile

    # Create a .env file in the same directory as this docker-compose.yml file
    env_file:
      - .env

    ports:
      - "${INVOKEAI_PORT:-9090}:9090"
    volumes:
      - ${HOST_INVOKEAI_ROOT:-~/invokeai}:/invokeai
    tty: true
    stdin_open: true
    ### Below is an example of passing alternative commands/scripts to the container. See documentation for examples.
    # command:
    #   - bash
    #   - -c
    #   - |
    #     echo "[$$(date)] exec: $$(ps -p1 -c -h)"
    #     invokeai-model-install --yes --default-only --config_file ${INVOKEAI_ROOT}/config_custom.yaml
    #     invokeai-nodes-web --host 0.0.0.0
